```c
int max(int a, int b)
{
    if (a >= b) { return a; } else { return b; }
}

int min(int a, int b)
{
    if (a <= b) { return a; } else { return b; }
}

#define BLUR_SIZE 1

for (int cur_row = 0; cur_row < height; ++cur_row) {
	
	for (int cur_col = 0; cur_col < width; cur_col += 3) {
		
		for (int blur_row = max(0, cur_row - BLUR_SIZE); blur_row <= min(height, cur_row + BLUR_SIZE); ++blur_row) {
			
			for (int blur_col = max(0, cur_col - BLUR_SIZE); blur_col <= min(width, cur_col + BLUR_SIZE); ++blur_col) {
				blurAreaSum += inputImg[width * blur_row + blur_col];
				blurAreaSize++;
			}
		}
		
		outputImg[width * cur_row + cur_col] = (blurAreaSum / blurAreaSize);
	}
}
```


										4.1 Архитектура GPU
	Состоит из массива потоковых мультипроцессоров (Streaming Multiprocessor, SM). SM состоит из множества
потоковых процессоров именуемых CUDA-ядрами. Также SM имеет блок управления и свою локальную память, которые
являются общими для его CUDA-ядер. Например, видеокарта Ampere A100 имеет 108 SM с 64 CUDA-ядрами каждый.
SM фрагментированы далее на блоки обработки по 16 ядер в каждом, т.е. в одном SM 4 блока обработки по 16 ядер:



typedef struct StreamingProcessor {
	
} CUDAcore;

typedef struct ProcessingBlock {
	CUDAcore cores[16];
} PB;

typedef struct StreamingMultiprocessor {
	PB block1;
	PB block2;
	PB block3;
	PB block4;
} SM;

typedef struct NVidia {
	SM sm_array[108];
} AmpereA100;

	Память видеокарты представлена двумя видами:
on-chip  - память SM;
off-chip - общие несколько гигабайт видеокарты.



										4.2 Диспетчеризация блоков
	Потоки присваиваются SM-ам поблочно. Количество одновременно запускаемых блоков зависит от видеокарты.
Видеокарта берет на себя заботу по планированию запуска блоков если их количество превышает доступные ресурсы.
Можно синхронизировать потоки лишь одного блока. Для синхронизации самих блоков надо воспользоваться Cooperative
Groups API.



										4.4 Warp'ы и аппаратная поддержка SIMD
	Потоки одного блока могут выполняться с разной скоростью, поэтому если код имеет фазы, выполнение которых
требует синхронности, то такая синхронность должна быть предусмотрена разрабом посредством __syncthreads().
В современных GPU когда блок присваивается MS'у, он далее делится warp'ы - единицы, состоящие из 32 потоков.
Разрабу надо хорошо понимать warp'ы, чтобы делать свой код лучше.
	Warp - это единица, которой орудует SM при диспетчеризации потоков. Например, есть три блока присвоенные
одному SM'у. Далее каждый из них делится на warp'ы для дальнейшей диспетчеризации. Каждый warp состоит из
32 потоков с индексами threadIdx:
	Warp 1: threadIdx.x = 0 по threadIdx.x = 31
	Warp 2: threadIdx.x = 32 по threadIdx.x = 63
	В общем случае warp 'N' начинается с потока 'N * 32' и заканчинается потоком '((N + 1) * 32) - 1'.
Если блок состоит из 256 потоков, тогда 256 / 32 = 8 warp'ов в одном блоке. Если блоки не кратны 32, тогда последний
warp будет добит неактивными потоками.
	Если блок состоит из двумерной структуры потоков, тогда они будут разложены в по принципе row-major прежде
чем разделены на warp'ы:
	Дано
	blockDim.x = 3
	blockDim.y = 3
	Тогда: y0:x0  y0:x1  y0:x2  y1:x0  y1:x1  y1:x2  y2:x0  y2:x1  y2:x2

	  .___1__2__3_> X
	  |	 ________
	0 |	|__|__|__|
	1 |	|__|__|__|
	2 |	|__|__|__|
	Y v

	SM'ы исполняют потоки в Warp'ах по принципу SIMD, т.е. в каждый момент времени все потоки выполняют
одну общую для всех инструкцию но этом обрабатывают разные данные.



										4.5 Control Divergence
	Если потоки внутри Warp'а идут по разным потокам исполнения, аппаратная поддержка SIMD выполнит несколько
проходов - по одному для каждого пути. На каждом проходе потоки из пула, идущего по другому пути
исполнения, будут бездействовать до тех пор, пока противоположный пул не завершит исполнение своего пути. Этот
эффект называется 'Control divergence' - расхождение управления.
	Дивергенция влияет на производительность, однако есть нюансы:
	1. если блок состоит из 256 потоков, тогда для обработки вектора A[1000] понадобится 4 блока. Один такой
	   блок содержит 256 / 32 = 4 Warp'а. В таком случае лишь последний Warp подвергается дивергенции.
	2. если обрабатываем изображение 62х76, то будет очень много потоков у краев изображения, которые
	   подвергнуться дивергенции.

